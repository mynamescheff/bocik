{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\odyn\\anak2\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Nie można odnaleźć określonej procedury'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images from the dataset\n",
    "def load_and_preprocess_data(data_dir, image_size=(256, 256)):\n",
    "    images = []\n",
    "    for image_file in os.listdir(data_dir):\n",
    "        image_path = os.path.join(data_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, image_size)\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load and preprocess the dataset (replace 'data_dir' with your dataset path)\n",
    "data_dir = \"img/not_labeled_stones\"\n",
    "images = load_and_preprocess_data(data_dir)\n",
    "\n",
    "# Data augmentation using Keras ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_images = []\n",
    "for image in images:\n",
    "    augmented_image = datagen.random_transform(image)\n",
    "    augmented_images.append(augmented_image)\n",
    "\n",
    "augmented_images = np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "\n",
    "\n",
    "\n",
    "def create_encoder(input_shape, embedding_size):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    embeddings = Dense(embedding_size)(x)\n",
    "    model = Model(inputs=base_model.input, outputs=embeddings)\n",
    "    return model\n",
    "\n",
    "# Set the input shape and embedding size for the encoder\n",
    "input_shape = (256, 256, 3)\n",
    "embedding_size = 128\n",
    "\n",
    "# Create the encoder\n",
    "encoder = create_encoder(input_shape, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 29s 561ms/step - loss: 0.5115\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.4286\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.3387\n",
      "7/7 [==============================] - 3s 387ms/step - loss: 0.3128\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.2943\n",
      "7/7 [==============================] - 3s 381ms/step - loss: 0.2870\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.2755\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.2670\n",
      "7/7 [==============================] - 3s 386ms/step - loss: 0.2650\n",
      "7/7 [==============================] - 3s 387ms/step - loss: 0.2604\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for contrastive learning (augmented images and their copies)\n",
    "augmented_data = np.concatenate((augmented_images, augmented_images))\n",
    "\n",
    "# Create labels for contrastive learning (1 for original images, 0 for copies)\n",
    "contrastive_labels = np.concatenate((np.ones(len(augmented_images)), np.zeros(len(augmented_images))))\n",
    "\n",
    "# Compile the model with the contrastive loss\n",
    "encoder.compile(optimizer='adam', loss=contrastive_loss)\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    encoder.fit(augmented_data, contrastive_labels, batch_size=batch_size, epochs=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bounding Box Generation\n",
    "import numpy as np\n",
    "\n",
    "def generate_bounding_boxes(embeddings, cluster_ids):\n",
    "    bounding_boxes = []\n",
    "\n",
    "    for cluster_id in np.unique(cluster_ids):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        indices = np.where(cluster_ids == cluster_id)[0]\n",
    "        x_min, y_min = np.min(embeddings[indices], axis=0)\n",
    "        x_max, y_max = np.max(embeddings[indices], axis=0)\n",
    "        bounding_box = [x_min, y_min, x_max, y_max]\n",
    "        bounding_boxes.append(bounding_box)\n",
    "\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21056\\2462573833.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbounding_boxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_bounding_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# bounding_boxes will be a list of bounding boxes, where each bounding box is represented as [x_min, y_min, x_max, y_max].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x_min: {x_min}, y_min: {y_min}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21056\\2476730919.py\u001b[0m in \u001b[0;36mgenerate_bounding_boxes\u001b[1;34m(embeddings, cluster_ids)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster_ids\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcluster_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mbounding_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Get embeddings for the entire dataset\n",
    "embeddings = encoder.predict(images)\n",
    "\n",
    "# Apply K-means clustering to group embeddings\n",
    "num_clusters = 5  # You can adjust the number of clusters based on your dataset\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "cluster_ids = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Generate bounding boxes for each detected object\n",
    "bounding_boxes = generate_bounding_boxes(embeddings, cluster_ids)\n",
    "\n",
    "# bounding_boxes will be a list of bounding boxes, where each bounding box is represented as [x_min, y_min, x_max, y_max]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Visualize detected objects and bounding boxes\n",
    "def visualize_objects_with_bboxes(images, cluster_ids):\n",
    "    for i, image in enumerate(images):\n",
    "        plt.imshow(image)\n",
    "        ax = plt.gca()\n",
    "        for cluster_id in np.unique(cluster_ids):\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "            indices = np.where(cluster_ids == cluster_id)[0]\n",
    "            x_min, y_min = np.min(embeddings[indices], axis=0)\n",
    "            x_max, y_max = np.max(embeddings[indices], axis=0)\n",
    "            x_min, x_max = int(x_min), int(x_max)\n",
    "            y_min, y_max = int(y_min), int(y_max)\n",
    "            rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "        plt.show()\n",
    "\n",
    "# Visualize the detected objects and bounding boxes\n",
    "visualize_objects_with_bboxes(images, cluster_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
